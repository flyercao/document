

JVM优化
https://blog.csdn.net/weixin_42447959/article/details/81637909
优化目标：内存占用;延迟;吞吐量
工具：应用日志、堆栈错误信息、GC日志、线程快照、堆快照
jps（找到应用进程pid）
jstate 内存分布
top -H -p（分析CPU占用高的线程）
jstack 分析线程状态和栈信息
jmap （分析类实例和空间占用，dump堆内存到文件）
建议：-Xms和-Xmx的值设置成相等，避免动态调整内存大小；新生代尽量设置大一些；根据gc日志，结合延迟目标，分配新生代大小和比例
短命大对象和数组；大循环创建对象；大批量处理数据；强引用缓存集合；长时间占用对象。

内存泄漏
Threadlocal泄漏


### 内存问题排查：
现象：应用接口查询间歇性超时，几个小时一次。
分析：查看应用性能监控，cpu、load、网络、磁盘都正常，发现老年代持续增长，间歇性出现fullgc；
1.jstat -gcutil命令查看垃圾回收变化，发现老年代空间间歇性增长。每次几十M。老年代调大了也不管用。
2.添加打印gc详情参数后，发现年轻代往老年代迁移的数据都是存活超过15次，而且年轻代中每个年龄的数据量没有明显异常（断代），排除大对象直接分配老年代和年轻代空间不足的情况。
3.jmap -histo:live命令分析存活对象分布情况，发现hashmap.Node实例数量在持续增长，gc后实例数量大幅减少。
基本确定是由于hashmap使用不当造成内存没有及时回收。通过代码分析发现是应用频繁从redis加载全量司机车辆数据到本地hashmap，并且采用removeAll、putAll的方式更新。
这种方式会导致HashMap的Node实例从年轻代迁移到老年代后，被频繁释放又创建，占用老年代内存空间。
采用增量的方式更新本地缓存，如果数据没有发现变化，则不更新，只更新有变化的这部分数据，使老年代的数据保持稳定。
修复后超时和fullgc问题解决，hashmap.Node实例数量也保持稳定，老年代空间也保持相对稳定。
**rt优先** 保障ygc不影响rt的情况下，尽量大年轻代，降低年轻代回收频率，减少老年代迁移。结合内存碎片、回收频率和回收时间等因素考虑。
**吞吐量优先** 较大的年轻代和较小的老年代，尽早回收短期对象，减少中期对象，老年代存放长期对象。

### CPU占用分析 
jps找到进程号,top -H -p pid 找到占用CPU高的线程，将线程号转换成16进制，jstack查看线程的堆栈。多次重复，分析耗时高的方法堆栈。
arths在线诊断工具，trace命令直接从上往下分析高耗时的方法调用。
arths通过jvm底层开放的attachation机制，连接到目标jvm，然后再Instrument基础上没使用Transformer对应用字节码进行增强

### 应用假死
现象：应用启动超时，线程假死。
分析：1.应用没有报错日志，应用进程还在，没有退出。2.分析日志，发现发布过程中，应用在初始化spring bean的过程中假死，线程无响应。3.检查了变更代码，没有发现明显异常。
jstack 查看线程状态，发现初始化bean的线程状态为blocked，然后分析线程堆栈是阻塞在MongoDB执行代码，进一步分析，发现该代码是在创建索引。
假设：创建索引是个耗时动作，导致应用启动线程被阻塞，应用出现假死。
验证：在线下人工后台创建索引，移除该部分代码。重新发布后，应用启动正常。
加强上线前codereview。加强对开发人员的培训，尤其是实习生和应届生。


### 活动应用性能优化
现状：单机压测qps在200不到，rt已经超过200ms，接口熔断了
目标：单机qps到5000，平均rt小于10ms，99%rt小于50ms。
排查：
现象：0.机器是4核8g；1.load到2；2.cpu20%；3.网络状态正常；4.rt超时 5.qps150
1. （日志异步）top和jstack命令，发现waiting业务线程，堆栈出现大量logback调用，结合arths工具，发现打印日志耗时几十ms。线程阻塞在ReentrantLock.lock方法。（logback已经配置了异步appender），分析阻塞原因。发现有个neverBlock属性，默认值为false。调用blockingQueue.put阻塞方法追加日志。如果为true，则通过blockingQueue.offer非阻塞方法追加日志。于是添加了neverBlock=true的配置。
qps到800，rt200ms以内。CPU30%；load5；rt超时
2. （异步发送kafka消息）同样发现了策略命中数量统计的方法耗时长，频繁多次发送kafka消息。优化成 disruptor异步发送和写日志发送。
qps在1000，dubbo线程数不足。
3. （Fastjson优化）还是top和jstack命令，发现大量出现JSON.toJSONString方法，结合arths工具，发现耗时0.1ms。调整为对象toString方法。
4. 发现线程不足，但是大量dubbo线程出于waiting状态，实际执行线程不到10 。
通过对dubbo线程分发模式进行研究，进行异步改造。结合服务端异步执行AsyncContext+客户端异步调用+客户端事件通知实现异步网关。（减少线程waiting时间，提高dubbo线程利用率，减少线程切换开销）
改造后内部rt降低到2ms+1ms，频繁ygc和fgc。
5. 采用高性能脚本引擎，替换Apache jexl；
6. hbase稳定性优化（关闭数据随机合并，指定夜间进行）
7. 订单状态查询dubbo接口优化，并行请求，future异步接受结果。
8. mysql分库分表，（几亿）手机号风险库分64个表

1. top -H -p pid 命令和  jstack命令，分析占CPU高的线程；发现是apache jexl在解析和aqs执行脚本（解释型脚本解析器，非常占CPU）；升级机器为8核16g机器，重新压测
qps到400；CPU80%；load10；每秒4次YGC，30ms，没有full gc
2. 2g内存，新生代680M；jstate -gcutil 分析内存回收情况，新生代快速占满回收，没有向老年代迁移；扩大内存到4g；
qps到500，load不变，rt下降到180ms，YGC评率降低每秒一次，20ms；ioutil升高。



系统流量
活动压测
机器配置
实时特征毫秒级
线上问题排查
系统设计，不合理
异地多活
spring bean
kafka消息队列


MQ选型：kafka与RocketMQ
partition数量
异地双活灾备设计方案
spring bean切入机制
