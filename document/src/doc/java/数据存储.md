
## mysql
**缓冲池优化**：InnoDB对传统的LRU算法做了一些优化，LRU列表中添加了midpoint位置，将缓冲池分为冷热两部分，两部分数据根据策略进行交换。（linkedList+HashMap实现LRU，或LinkedHashMap实现）
Checkpoint：由于数据库采用write ahead log策略，需要通过Checkpoint来强制刷新内存数据到磁盘，缩短数据库启动和恢复时间。缓冲池溢出脏页、redo log满时，会强制CheckPoint。
InsertBuffer：对于非唯一的非聚集索引，插入时如果该页不在缓存中，则先放到InsertBuffer对象，在一定条件下，与索引页进行merge，可以将多个插入合并成一次操作。提高写入性能。
DoubleWrite：保障数据完整性。在对脏页进行刷新时，先把脏数据复制到内存中的doublewrite buffer，然后分两次写入磁盘的doublewrite（顺序写），最后写入数据到数据页（分散写）。
异步IO：异步IO在发送完IO请求后可以继续发出新的IO请求；且AIO可以进行IO Merge。
刷新邻接页：当刷新一个脏页时，InnoDB会检测该页所在区的所有页，如果是脏页，那么一起进行刷新。这样可以利用AIO合并多个IO操作。
innoDB引擎：完整支持ACID事务，在线事务处理。表锁、行锁；通过多版本并发控制MVCC来获得高并发性，并实现了4种隔离级别，默认Read Repeatable，使用next-key-locking间隙锁的策略来避免幻读。
特性
事务机制
Atom原子性：当事务对数据库进行修改时，InnoDB会生成对应的undo log；如果事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。当发生回滚时，InnoDB会根据undo log的内容做与之前相反的工作。
Durability持久性：当数据修改时，除了修改Buffer Pool中的数据，还会在redo log记录这次操作；当事务提交时，会调用fsync接口对redo log进行刷盘。如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复。
Isolation隔离性:InnoDB通过锁机制（含next-key lock）和MVCC机制（包括数据的隐藏列、基于undo log的版本链、ReadView）保证多并发下的数据隔离。MVCC最大的优点是读不加锁，因此读写不冲突，并发性能好。主要基于一下技术：
```
隐藏列：InnoDB中每行数据都有隐藏列，隐藏列中包含了本行数据的事务id、指向undo log的指针
基于undo log的版本链：每行数据的隐藏列中包含了指向undo log的指针，而每条undo log也会指向更早版本的undo log，从而形成一条版本链
ReadView：通过隐藏列和版本链，MySQL可以将数据恢复到指定版本；进行读操作时，会将读取到的数据中的事务id与快照事务id比较，从而判断数据对该ReadView是否可见，即对事务A是否可见。数据的事务id>readview_id,则不可见；生成readview时，数据的事务id已提交，则可见。
读未提交（Read Uncommit）：读到了其他事务还未提交的数据，出现了脏读。
读已提交（Read Commit）：避免脏读（读未提交数据）。事务每次select前生成readview，当select时，对于未提交的数据，数据事务id还未提交，该数据对ReadView不可见，则根据指针指向的undo log查询上一版本的数据。
可重复读（Repeatable Read）：避免不可重复读。利用MVCC解决了快照读幻读，利用间隙锁解决了当前读幻读。事务首次select前生成readview，当select时，对于未提交的数据，数据事务id还未提交或小于readview事务id，该数据对ReadView不可见，则根据指针指向的undo log查询上一版本的数据。
串行读（Serializable）：MVCC避免幻读的机制与避免不可重复读非常类似，事务在首次select某范围内数据时生成readview，之后在此select该范围数据时，根据首次生成的readview对数据进行可见性判断，对于新插入的数据，事务根据其指针指向的undo log查询上一版本的数据，发现该数据并不存在，从而避免了幻读。


RC与RR都使用了MVCC，主要区别在于RR是在事务开始后第一次执行select前创建ReadView，直到事务提交都不会再创建，RR可以避免脏读、不可重复读和幻读。RC每次执行select前都会重新建立一个新的ReadView，如果中间有其他事务提交的话，后续的select是可见的，可以避免脏读。
对于加锁读select...for update，由于事务对数据进行加锁读后，其他事务无法对数据进行写操作，因此可以避免脏读和不可重复读。通过next-key lock，不仅会锁住记录本身(record lock的功能)，还会锁定一个范围(gap lock的功能)，因此，加锁读同样可以避免脏读、不可重复读和幻读，保证隔离性。
如果在事务中第一次读取采用非加锁读，第二次读取采用加锁读，则如果在两次读取之间数据发生了变化，两次读取到的结果不一样，因为加锁读时不会采用MVCC。
怎么解决幻读？

在Innodb引擎中，每条聚集索引都会有两个隐藏字段：trx_id和roll_pointer，每次事务对一条记录进行改动时，就会将事务id赋值给trx_id，并且会将旧数据写入一条undo日志，每条undo日志也都有一个roll_pointer属性，可以将这些undo日志都连起来，串成一个链表，undo日志的写入采用头插法，新数据在前。
快照读： MVCC中有一个ReadView的概念，其中记录了生成ReadView时的活跃事务id列表:m_ids、最小事务id:min_trx_id、将要分配给下一个事务的id:max_trx_id、生成ReadView的事务id:creator_trx_id。如果被访问版本的trx_id与creator_trx_id相同或者小于min_trx_id，则可以访问；如果被访问版本的trx_id大于等于max_trx_id，则不能访问；如果被访问版本的trx_id在min_trx_id和max_trx_id之间，则当trx_id不在m_ids中时才能访问。
当前读： InnoDB存储引擎有三种锁：Record lock：单个行记录上的锁；Gap lock：间隙锁，锁定一个范围，不包括记录本身；Next-key lock：record+gap 锁定一个范围，包含记录本身。innodb对于行的查询使用next-key lock，当查询的索引含有唯一属性时，将next-key lock降级为record key。
```
Consistency一致性：一致性是事务追求的最终目标：前面提到的原子性、持久性和隔离性，都是为了保证数据库处于正确的状态。

https://img2018.cnblogs.com/blog/1174710/201901/1174710-20190128201034603-681355962.png
https://www.cnblogs.com/kismetv/p/10331633.html
主键索引、查询优化
全值匹配、最左前缀、索引列无计算、范围索引失效、空值不等失效、like最右、覆盖查询（不用回表）、explain法宝
查询优化：

使用索引最左匹配原则，选择性大的列放前面。
聚集函数字段加索引。
查询满足后，使用limit提前终止。
like左边不要使用%，会导致索引失效。
where查询时，索引列不要做运算或函数的参数。
尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描。
避免在WHERE子句中使用 != 或 <>操作符，否则将引擎放弃使用索引而进行全表扫描。
查询尽量使用覆盖索引，减少回表。
使用 JOIN 级联查询时，应该保证两表中 JOIN 的字段已建立过索引且类型相同。
尽可能的使用 NOT NULL：NULL会占用额外的空间来记录其值是否为空。
IP地址 存成 INT UNSIGNED。
拆分大的 DELETE 或 INSERT 语句，避免长时间锁表。
不用外键，不用UNIQUE，由程序保证约束。
使用OR时，前后条件都必须是索引，否则索引失效。
OR改写成IN : OR的效率是n级别，IN的效率是 log(n)级别。
尽量使用 count(*)计算数量 : 列的偏移 量决定性能，列越靠后，访问的开销越大。由于 count(*)的算法与列偏移量无关，所以 count(*) 最快，count(最后列)最慢

mysql主从延迟：mysql的主从复制都是单线程的操作，DDL导致线程卡死。解决方案：从库SSD随机读；业务低峰期执行DDL；
分库分表jbdc-sharding

## redis
https://blog.csdn.net/whereisherofrom/category_9282660.html
（https://www.cnblogs.com/4AMLJW/p/redis202004161644.html）
![github](https://pic4.zhimg.com/80/v2-d1128bb6e62db58955215c4c05ac1eab_1440w.jpg)
#### String 
文本通过SDS结构保存：
内部编码包括：int数组；emdstr小于44字节文本；raw：长文本最大512M
缓存K-V结构；计数器；setnx实现分布式锁；二进制安全，保存二进制
#### List
编码包括LINKEDLIST链表和ZIPLIST压缩列表。
有序列表，可实现栈、队列、有限集合和消息队列等结构。

高性能分页；简单消息队列；
#### Hash
编码包括ziplist或者hashtable（数组+链表）
支持扩容和缩容；渐进式rehash，把原hashtable数据rehash到新的hashtable，过程中会记录rehash的index，进行可中断渐进式扩容或缩容。 
#### Set
编码是intset或者hashtable（value为空）
intset是一个整数集合，保存16位、32位、64位三种长度的整数。
无序，无重复集合。全局去重；集合的交集、并集、差集的操作。
#### Sorted Set
有序集合编码是ziplist或skiplist与dict的结合。
有序性；快速查找
排行榜；优先级队列；

#### 底层编码
简单动态字符串SDS：长度属性；避免缓冲区溢出；预分配和惰性释放，减少频繁内存分配；二进制安全；
链表linkedlist：双端；无环；长度属性；支持多类型；
字典hashtable：支持扩容和缩容；渐进式rehash，把原hashtable数据rehash到新的hashtable，过程中会记录rehash的index，进行可中断渐进式扩容或缩容。 
跳跃表skiplist：有序数据结构，节点有很多层，节点的层数不固定，每层维护指向同层下一个节点的指针，每个节点包含指向上一节点的后退指针。
整数集合intset：整数集合的每个元素都是 contents 数组的一个数据项，它们按照从小到大的顺序排列，并且不包含任何重复项。可以保存类型为int16_t、int32_t 或者int64_t 的整数值。
压缩列表ziplist：压缩列表并不是对数据利用某种算法进行压缩，而是将数据按照一定规则编码在一块连续的内存区域，目的是节省内存。

Bitmap：位图（底层结构为字符串），保存大规模的Boolean值。签到、在线状态等；BITCOUNT全局去重计数；BITOP 命令支持 AND 、 OR 、 NOT 、 XOR 操作；可以通过插件支持redis版BloomFilter
HyperLogLog：极高性能的全局去重计数（估算）。PFADD添加；PFCOUNT估算基数；PFMERGE 合并多个。
GeoHash：底层为ZSet结构。地理空间(geospatial)以及索引半径查询。两点距离；经纬度返回Geohash；Geohash返回相近经纬度；圈内的所有位置；   
pub/sub：消息生产者消费者模式，数据可靠性无法保证，不建议生产环境使用。
pipeline：批量提交命令，批量返回结果，期间独占连接，返回结果会占用更多内存。
Lua脚本：多个脚本一次请求，减少网络开销；原子操作，无需担心竞争问题；复用，脚本会缓存在服务器，无需每次传输。
事务：Redis 事务的本质是一组命令的集合；watch来实现乐观锁，在事务中不能改变被watch（锁）的值。命令错误则不执行，执行错误继续执行所有命令。
内存回收：通过引用计数法判断是否回收。清除策略包括：1.volatile-lru（LRU移除即将过期key）2.allkeys-lru（LRU移除所有key）3.volatile-random（随机移除即将过期key）4.allkeys-random（随机移除过期key）5.volatile-ttl（顺序移除即将过期）6.noeviction 不移除数据，报错（默认）
内存共享：为了节省内存，不同的key指向同一个value，只支持整数值的字符串对象。
### 持久化：
RDB：bgsave命令手动；配置自动定时fork子进程，把数据以快照的形式保存在磁盘上。效率高，备份文件，恢复快；占内存，数据丢失；
AOF：将每一个收到的写命令都通过write函数写入缓冲区，根据同步策略追加到文件中，定期对AOF文件进行重写，保持最小命令量。保证数据不丢失，基本不影响客户端命令执行。文件大，恢复效率低。
RDB-AOF：Redis 4.0新增了混合持久化。打开之后，aof rewrite 的时候就直接把 rdb 的内容写到 aof 文件开头。
生产配置：master完全关闭持久化，这样可以让master的性能达到最好；slave关闭快照持久化，开启AOF，然后关闭AOF的自动重写，然后添加定时任务，在每天Redis闲时（如凌晨12点）调用bgrewriteaof。

### redis cluster集群：高可用高扩展的无中心结构（分片+主备）；client随机选择节点发起请求，节点会进行moved重定向，
容错：半数以上的master节点投票确认节点失联。1.master和slave都失联则集群不可用（可配置兼容部分失败）。2.半数master失联则不可用。
选举：1.currentEpoch表示集群状态变更的递增版本号，节点的currentEpoch越大，表示数据越新。集群中所有节点的 currentEpoch 最终会达成一致。2.选举前，从节点会等待一段时间，数据越新，等待越短。节点把自己currentEpoch+1，广播给所有master进行投票；3.master节点 2s内不会重复为同一个master进行投票。
数据分布
一致性哈希。对每一个key进行hash运算，被哈希后的结果在哪个token的范围内，则按顺时针去找最近的节点，这个key将会被保存在这个节点上。缺点（翻倍伸缩才能保证负载均衡）。
虚拟槽分区。Redis Cluster采用的分区方式。把16384槽按照节点数量进行平均分配，由节点进行管理，对每个key按照CRC16规则进行hash运算，把hash结果对16383进行取余。可以对数据打散，又可以保证数据分布均匀

### codis
只是一个转发代理中间件，可以启动多个Codis 实例，供客户端使用，每个 Codis 节点都是对等的。
虚拟槽分区：每个槽位都会唯一映射到后面的多个 Redis 实例之一，Codis 会在内存维护槽位和Redis 实例的映射关系。这样有了上面 key 对应的槽位，那么它应该转发到哪个 Redis 实例。
Codis 将槽位关系存储在 zk 中，也支持etcd
扩容：支持动态、自动扩容。迁移过程中，先请求原节点，原节点强制对该key进行迁移，之后再转发到新节点。
缺点：部分命令不支持，（keys、BLPOP、PUBLISH），单key容量不宜过大，性能比原生稍差、依赖zk保障可用性、对新功能支持不友好
优点：集群原理简单，后台管理方便，运维友好。

缓存一致性：更新数据库，再删缓存,失败则发消息，重新删除。终极方案，设置超时，订阅binlog，删除key。
缓存穿透：外部的恶意攻击时，未命中缓存，直接查询DB。使用BloomFilter排除不存在对象。
缓存击穿：某个热点数据失效，大量请求会穿透到DB。使用互斥锁（SETNX）查询DB和更新缓存。多个热点 key 同时失效，失效时间考虑随机数。
缓存雪崩：快速失败+集群模式来保证高可用。
过期策略：定期删除+惰性删除。
淘汰机制：报错，LRU，random，TTL

## mongo
文档型、模式自由、高性能、高可用、高扩展、支持事务、分布式数据库。
性能：1.充分使用系统内存作为缓存，内存不够才会写磁盘；2.索引直接关联地址，无需回表查询；3.内联数据模式，无需关联查询，数据相对集中。4.集群模式；
分片：https://img2020.cnblogs.com/blog/630480/202003/630480-20200303232850387-60758810.png
mongos：数据路由，和客户端打交道的模块。
config server：所有存、取数据的方式，所有shard节点的信息，分片功能的一些配置信息。
shard：真正的数据存储位置，以chunk（64M）为单位存数据。
Chunk：MongoDB会把数据分为chunks作为最小管理单位。1.超过size时，会被后台进程分裂；2.后台进程会自动平衡分片之间的chunks。
数据分区
分片键shard key：片键必须是一个索引（单个或组合索引）。1.按照范围分片，分布不均，导致热点；2.基于哈希分片，分布均匀，不利于范围查询。分片键选择建议：大方向随机递增，小范围随机分布。

单文档事务
Atom（原子性）：journal 机制来实现，支持单文档的执行、提交和回滚；如果是多文档，需要合并成一个文档。
Consistency（一致性）:通过Write Concern写策略，Read Concern读策略和Read Preference从哪读来实现灵活的一致性。
Isolation（隔离性）：读已提交，通过读写锁 + snapshot+ MVCC实现，与mysql类似。一个事务开始时，只能“看见”已经提交的事务所做的修改，会出现不可重复读（non-repeatable read）现象。
durability（持久性）：通过journal日志和Write Concern写入策略可以实现灵活的分布式持久性。
4.x版本支持多文档事务和分布式事务。

http://quarterback.cn/hbase%E6%A6%82%E8%BF%B0/
## Hbase
java开发构建在HDFS之上支持实时读写、随机访问、超大规模数据集的分布式、面向列的存储系统。
面向列：按列存储，避免加载无用列，节省IO；
多版本：单元格（table, rowkey, column-family, column, timestamp）可以根据时间戳保存多个版本的值，保留最近N个版本或最近时间。
灵活模式：表名和列族固定，写入时动态创建列，每行的列都可以不同。
压缩：支持列族压缩，以及选择压缩算法。
读/写强一致性：表中每行数据只会存在一个Region，并且读写都只在这一个region上。
扩展性：数据自动分区（Region自动按照rowkey范围拆分）；负载均衡（Region拆分后重新分配到其他server）；增加机器扩展集群
高可靠：多副本（依靠HDFS提供的副本和自动故障转移机制）；Write Ahead Log(预写日志)
高性能：顺序写入WAL文件到磁盘，定期flush硬盘（LSM数据结构，按Rowkey有序存储）；优先读MemStore(写缓存)->BlockCache(读缓存)->StoreFile(文件)；BloomFilter过滤可能存在rowkey的StoreFiles。
事务：目前只支持行级事务，强一致性，满足的ACID特性。单行操作原子性，无锁CAS操作保障原子性；其采用了WAL（Write Ahead Log）策略，以及通过锁和MVCC机制来实现并发控制。
  
可用性：WAL恢复较慢，期间该region不可用。
性能：Major compaction占用IO等资源，影响性能。查询多个StoreFiles做查询，性能较差。
功能：KV结构查询，不支持SQL。
## 对比选型
MySQL(CA)：结构化数据；严格事务，数据一致性强；多表关联复杂查询；无官方分库分表；数据量瓶颈；(量级小、读多写少)
redis(CP)：高性能，10万qps；单线程，原子性；数据结构丰富；自动过期，当缓存；弱持久化；纯内存，成本高；数据量有限；（量级小，读多写多）
MongoDB(CP)：非结构化数据；数据分片扩展，海量数据；主从切换高可用；（自动过期、地理位置）无事务；单文档嵌套简单查询；（海量级，读多写多）
Hbase(CP)：列式存储；空列不存储；无限制列，可扩展列；多版本；高性能写入；只能查询Key；（海量级，写多读少）
ElasticSearch:实时索引；复杂条件索引；

HashMap：哈希结构，定时dump或日志持久化。O(1)读写性能非常高。只能全KEY匹配，无范围查询。写快读快。hash碰撞性能降低。数据全加载内存。
B+ Tree：一整颗n叉树，实时写入。O(n)支持有序遍历和范围扫描。写慢读快。数据持久化到磁盘（随机写），内存做缓存。
LSM Tree：N棵n叉树，定时合并。支持随机读写和顺序扫描。写快读慢。写内存，批量持久化到磁盘（顺序写），内存做缓存。