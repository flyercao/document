
## cap理论

https://blog.csdn.net/suifeng3051/article/details/48053965
## kafka
基于push-subscribe的分布式消息系统。应用在消息系统、日志收集、数据采集分发、流式处理等场景。
高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒
可扩展性：kafka集群支持热扩展
持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失
容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）
高并发：支持数千个客户端同时读写

Replications数据持久化副本数量，至少为2。只有一个partition的副本会被选举成leader作为读写用。
Partition：Kafka中的topic是以partition的形式存放的，数据实际存储在log文件。Partition的数量决定了topic log的数量
一个partition只能被一个消费者消费，一个消费者可以消费多个partition。partitions >  consumers

Producers客户端设置key自己控制着消息被推送到哪些partition。支持批量发送、异步发送、结果future、acks确认副本数、
Consumers通过offset来决定读取哪条数据，通过提交offset表示消费完成的位置。
partition：每个主题可以分为多个partition，每个partition实际存储为append log；每条消息根据时间顺序分配一个单调递增的offset，以日志的形式顺序追加到文件尾部；由生产者决定消息发送到哪个partition。

### 高可用
可靠性：通过acks参数确保生产者写入成功，消费者根据offset读取和提交消息位置，保证消费成功。
备份：提高了Kafka集群的可靠性、稳定性、容错性。备份数量为n的集群允许n-1个节点失败。
### 高性能
压缩：消息头部添加了一个描述压缩属性字节，GZIP或Snappy格式对消息集合进行压缩。Producer端进行压缩之后，在Consumer端需进行解压。
持久化：依赖操作系统缓存；使用字节而不是对象，减少内存占用。  
性能：采用日志结构支持有限的操作，保证常数时间的读写性能。 
Memory Mapped Files内存文件映射：直接利用操作系统的Page来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上。 
序列化：server端直接出列字节，无需序列化和反序列化处理。  
批量：Producer批量发送消息集合；server端是以消息块的形式追加消息到log中；consumer在查询的时候也是一次查询大量的线性数据块。  
零拷贝：依赖操作系统提供的零拷贝sendfile机制，实现操作系统页面缓存和socket之间的数据传递。  

https://blog.csdn.net/dingshuo168/article/details/102970988
https://www.wwwbuild.net/huangtalkit/23928.html
## RocketMQ
### 对比RocketMQ### 顺序：
producer：客户端在发送的时候使用单线程，根据queue选择器和排序id，把有顺序关系的消息都发送到同一个queue上。
broker：客户端采用同步发送消息，broker收到消息后，顺序写入commitLog文件，保证消息在文件中是有序。
consumer：1.同一个queue只允许一个consumer消费；2.消息到达consumer后回被放进缓存队列，consumer增加了互斥锁，同一时间同一个queue只会有一个线程在处理；
3.consumer线程处理超时或失败时，该consumer会一直重试处理，直到超过最大次数，然后返还broker，broker直接把消息放死信队列，而不是重试队列。
问题：1.消息分配不均，导致消息堆积；2.broker宕机需要切换queue时，如果原consumer有消息对接，可能后发送的消息被先消费了。  
### 事务：RocketMQ支持事务，kafka不支持； 
 producer发送带有唯一key的事务消息，Broker保存到预提交队列，consumer不可见。返回事务结果给producer；
 producer执行本地事务，根据情况想broker发送commit或rollback；
 broker收到commit指令，则根据消息key从预提交队列移除消息，重新正式写入commitLog。收到rollback指令，则从预提交队列移除消息。
 broker重试未收到producer指令，会定时重试调用Producer.checkLocalTransaction，根据producer的事务状态决定commit或rollback。

### 重试：RocketMQ有重试队列和死信队列，支持失败重试机制；kafka不支持
延时消息：1.producer修改topic名称以及队列信息（根据延时级别决定发送到哪个级别的延时队列（18个level））；2.根据队列信息，转发到对应的延时Queue；3.延时服务后台线程消费延时Queue里的消息，改回真实的TOPIC；4.重新提交消息，写入commitLog；5. 把消息投递到对应的consumer Queue；  

消息查询：RocketMQ支持根据key查询消息内容，kafka不支持
消息回溯：RocketMQ支持按时间回溯；kafka支持offset回溯；

### 选型
1. 功能维度
延迟消息；顺序消息；事务消息；重试队列；死信队列；消费模式（集群、广播）；消息回溯；幂等性（At most once、At least once）
2.性能维度
吞吐量；时延
3.可靠性
消息丢失（ack）；故障恢复；集群规模；社区活跃
4.运维管理
安全、权限、监控、告警、容灾、多机房
5.生态

RocketMQ：功能丰富（分区数量、事务消息、失败重试、延迟消息、回溯、不限制消费者数量），毫秒级响应；适合在线业务场景
kafka：大数据日志场景功能丰富、兼容性好、性能高；适合日志、流式处理、大数据场景。

数据可靠性：kafka支持主从自动切换，RocketMQ不支持Master宕机Slave自动切换；  
性能：kafka写入百万级，RocketMQ十万级；kafka producer批量提交消息  
分区数量：kafka支持不超过64，影响性能，RocketMQ不影响性能；kafka每个topic partition对应一个文件，RocketMQ所有消息写入一个commitLog文件；

## zookeeper
zookeeper：高可用、高性能、强一致性的分布式开源协调服务。适合同步服务、配置维护和集群命名和管理。
目录树结构，节点可以存储少量数据；
节点数据只能原子操作
节点类型：1.永久节点，显式增加和删除；2.临时节点，生命周期跟session绑定，断开后会自动删除节点；
节点自增：节点支持有序自增。
监听节点：客户端可以watch节点的增、删、改操作，客户端只收到一条消息。
分布式锁：1.客户端申请锁目录下创建临时有序节点，并返回该目录所有子节点；2.如果自己是排第一，则获取到锁，执行业务代码；3.如果不是排第一，则加锁失败；4.监听前一个临时节点的删除事件，直到收到通知消息；5.业务代码执行完，主动删除当前节点。如果创建改临时节点的客户端断开连接，zookeeper会清除该临时节点；6。zookeeper发现临时节点被删除，会通知监听该节点的客户端重新获取锁节点列表



## Sharding-JDBC
